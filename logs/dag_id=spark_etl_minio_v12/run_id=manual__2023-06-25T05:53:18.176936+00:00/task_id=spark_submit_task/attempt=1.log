[2023-06-25T05:53:18.937+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: spark_etl_minio_v12.spark_submit_task manual__2023-06-25T05:53:18.176936+00:00 [queued]>
[2023-06-25T05:53:18.946+0000] {taskinstance.py:1084} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: spark_etl_minio_v12.spark_submit_task manual__2023-06-25T05:53:18.176936+00:00 [queued]>
[2023-06-25T05:53:18.946+0000] {taskinstance.py:1282} INFO - 
--------------------------------------------------------------------------------
[2023-06-25T05:53:18.946+0000] {taskinstance.py:1283} INFO - Starting attempt 1 of 6
[2023-06-25T05:53:18.946+0000] {taskinstance.py:1284} INFO - 
--------------------------------------------------------------------------------
[2023-06-25T05:53:18.959+0000] {taskinstance.py:1303} INFO - Executing <Task(SparkSubmitOperator): spark_submit_task> on 2023-06-25 05:53:18.176936+00:00
[2023-06-25T05:53:18.964+0000] {standard_task_runner.py:55} INFO - Started process 25122 to run task
[2023-06-25T05:53:18.967+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'spark_etl_minio_v12', 'spark_submit_task', 'manual__2023-06-25T05:53:18.176936+00:00', '--job-id', '225', '--raw', '--subdir', 'DAGS_FOLDER/spark_job_minio_v1.py', '--cfg-path', '/tmp/tmp_udxk6yo']
[2023-06-25T05:53:18.967+0000] {standard_task_runner.py:83} INFO - Job 225: Subtask spark_submit_task
[2023-06-25T05:53:18.978+0000] {warnings.py:109} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:250: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2023-06-25T05:53:19.014+0000] {task_command.py:388} INFO - Running <TaskInstance: spark_etl_minio_v12.spark_submit_task manual__2023-06-25T05:53:18.176936+00:00 [running]> on host a8d69ab09d2d
[2023-06-25T05:53:19.069+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=spark_etl_minio_v12
AIRFLOW_CTX_TASK_ID=spark_submit_task
AIRFLOW_CTX_EXECUTION_DATE=2023-06-25T05:53:18.176936+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-06-25T05:53:18.176936+00:00
[2023-06-25T05:53:19.078+0000] {base.py:73} INFO - Using connection ID 'spark_conn' for task execution.
[2023-06-25T05:53:19.080+0000] {spark_submit.py:341} INFO - Spark-Submit cmd: spark-submit --master spark://spark:7077 --jars local:///opt/spark/jars/hadoop-aws-3.2.0.jar,local:///opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar --name arrow-spark /opt/***/dags/spark_etl_spark_minio.py
[2023-06-25T05:53:20.046+0000] {spark_submit.py:492} INFO - WARNING: An illegal reflective access operation has occurred
[2023-06-25T05:53:20.047+0000] {spark_submit.py:492} INFO - WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
[2023-06-25T05:53:20.047+0000] {spark_submit.py:492} INFO - WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
[2023-06-25T05:53:20.047+0000] {spark_submit.py:492} INFO - WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
[2023-06-25T05:53:20.047+0000] {spark_submit.py:492} INFO - WARNING: All illegal access operations will be denied in a future release
[2023-06-25T05:53:20.291+0000] {spark_submit.py:492} INFO - Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
[2023-06-25T05:53:20.291+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:20 WARN DependencyUtils: Local jar /opt/spark/jars/hadoop-aws-3.2.0.jar does not exist, skipping.
[2023-06-25T05:53:20.291+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:20 WARN DependencyUtils: Local jar /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar does not exist, skipping.
[2023-06-25T05:53:21.117+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SparkContext: Running Spark version 3.2.0
[2023-06-25T05:53:21.179+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2023-06-25T05:53:21.265+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO ResourceUtils: ==============================================================
[2023-06-25T05:53:21.265+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO ResourceUtils: No custom resources configured for spark.driver.
[2023-06-25T05:53:21.266+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO ResourceUtils: ==============================================================
[2023-06-25T05:53:21.266+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SparkContext: Submitted application: arrow-spark
[2023-06-25T05:53:21.286+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2023-06-25T05:53:21.297+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO ResourceProfile: Limiting resource is cpu
[2023-06-25T05:53:21.297+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2023-06-25T05:53:21.346+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SecurityManager: Changing view acls to: default
[2023-06-25T05:53:21.346+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SecurityManager: Changing modify acls to: default
[2023-06-25T05:53:21.347+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SecurityManager: Changing view acls groups to:
[2023-06-25T05:53:21.347+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SecurityManager: Changing modify acls groups to:
[2023-06-25T05:53:21.347+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(default); groups with view permissions: Set(); users  with modify permissions: Set(default); groups with modify permissions: Set()
[2023-06-25T05:53:21.745+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO Utils: Successfully started service 'sparkDriver' on port 37083.
[2023-06-25T05:53:21.796+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SparkEnv: Registering MapOutputTracker
[2023-06-25T05:53:21.827+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SparkEnv: Registering BlockManagerMaster
[2023-06-25T05:53:21.844+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2023-06-25T05:53:21.844+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2023-06-25T05:53:21.849+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2023-06-25T05:53:21.872+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-81d1e150-fd7c-4bcf-a833-567df0d0ce08
[2023-06-25T05:53:21.891+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2023-06-25T05:53:21.905+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:21 INFO SparkEnv: Registering OutputCommitCoordinator
[2023-06-25T05:53:22.130+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2023-06-25T05:53:22.130+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[2023-06-25T05:53:22.130+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[2023-06-25T05:53:22.131+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[2023-06-25T05:53:22.131+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[2023-06-25T05:53:22.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
[2023-06-25T05:53:22.141+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO Utils: Successfully started service 'SparkUI' on port 4046.
[2023-06-25T05:53:22.204+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://a8d69ab09d2d:4046
[2023-06-25T05:53:22.220+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO SparkContext: Added JAR local:///opt/spark/jars/hadoop-aws-3.2.0.jar at file:/opt/spark/jars/hadoop-aws-3.2.0.jar with timestamp 1687672401109
[2023-06-25T05:53:22.220+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO SparkContext: Added JAR local:///opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar at file:/opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar with timestamp 1687672401109
[2023-06-25T05:53:22.396+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark:7077...
[2023-06-25T05:53:22.453+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO TransportClientFactory: Successfully created connection to spark/172.19.0.10:7077 after 28 ms (0 ms spent in bootstraps)
[2023-06-25T05:53:22.533+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20230625055322-0001
[2023-06-25T05:53:22.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/0 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:22.538+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/0 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:22.548+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42693.
[2023-06-25T05:53:22.548+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO NettyBlockTransferService: Server created on a8d69ab09d2d:42693
[2023-06-25T05:53:22.548+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2023-06-25T05:53:22.553+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a8d69ab09d2d, 42693, None)
[2023-06-25T05:53:22.558+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO BlockManagerMasterEndpoint: Registering block manager a8d69ab09d2d:42693 with 434.4 MiB RAM, BlockManagerId(driver, a8d69ab09d2d, 42693, None)
[2023-06-25T05:53:22.564+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a8d69ab09d2d, 42693, None)
[2023-06-25T05:53:22.564+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a8d69ab09d2d, 42693, None)
[2023-06-25T05:53:22.605+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/0 is now RUNNING
[2023-06-25T05:53:22.808+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[2023-06-25T05:53:23.095+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2023-06-25T05:53:23.122+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:23 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2023-06-25T05:53:25.061+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:50532) with ID 0,  ResourceProfileId 0
[2023-06-25T05:53:25.181+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:38409 with 366.3 MiB RAM, BlockManagerId(0, 172.19.0.9, 38409, None)
[2023-06-25T05:53:25.233+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 ERROR TaskSchedulerImpl: Lost an executor 0 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:25.303+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/0 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:25.303+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/0 removed: Command exited with code 1
[2023-06-25T05:53:25.304+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/1 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:25.305+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/1 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:25.306+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO BlockManagerMaster: Removal of executor 0 requested
[2023-06-25T05:53:25.306+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 0
[2023-06-25T05:53:25.310+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO BlockManagerMasterEndpoint: Trying to remove executor 0 from BlockManagerMaster.
[2023-06-25T05:53:25.311+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(0, 172.19.0.9, 38409, None)
[2023-06-25T05:53:25.332+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/1 is now RUNNING
[2023-06-25T05:53:26.876+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO CodeGenerator: Code generated in 127.999692 ms
[2023-06-25T05:53:26.906+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2023-06-25T05:53:26.922+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2023-06-25T05:53:26.922+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)
[2023-06-25T05:53:26.922+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO DAGScheduler: Parents of final stage: List()
[2023-06-25T05:53:26.924+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO DAGScheduler: Missing parents: List()
[2023-06-25T05:53:26.927+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:26 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2023-06-25T05:53:27.009+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 11.7 KiB, free 434.4 MiB)
[2023-06-25T05:53:27.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
[2023-06-25T05:53:27.038+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on a8d69ab09d2d:42693 (size: 6.2 KiB, free: 434.4 MiB)
[2023-06-25T05:53:27.041+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1427
[2023-06-25T05:53:27.051+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2023-06-25T05:53:27.052+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2023-06-25T05:53:27.350+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53518) with ID 1,  ResourceProfileId 0
[2023-06-25T05:53:27.450+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:40965 with 366.3 MiB RAM, BlockManagerId(1, 172.19.0.9, 40965, None)
[2023-06-25T05:53:27.523+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 ERROR TaskSchedulerImpl: Lost an executor 1 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:27.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/1 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:27.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/1 removed: Command exited with code 1
[2023-06-25T05:53:27.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/2 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:27.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/2 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:27.587+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
[2023-06-25T05:53:27.587+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO BlockManagerMaster: Removal of executor 1 requested
[2023-06-25T05:53:27.587+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 1
[2023-06-25T05:53:27.587+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, 172.19.0.9, 40965, None)
[2023-06-25T05:53:27.605+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/2 is now RUNNING
[2023-06-25T05:53:29.416+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53532) with ID 2,  ResourceProfileId 0
[2023-06-25T05:53:29.512+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:40917 with 366.3 MiB RAM, BlockManagerId(2, 172.19.0.9, 40917, None)
[2023-06-25T05:53:29.564+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 ERROR TaskSchedulerImpl: Lost an executor 2 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:29.620+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/2 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:29.621+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/2 removed: Command exited with code 1
[2023-06-25T05:53:29.621+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
[2023-06-25T05:53:29.621+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO BlockManagerMaster: Removal of executor 2 requested
[2023-06-25T05:53:29.621+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 2
[2023-06-25T05:53:29.621+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, 172.19.0.9, 40917, None)
[2023-06-25T05:53:29.621+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/3 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:29.622+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/3 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:29.650+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/3 is now RUNNING
[2023-06-25T05:53:31.422+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53550) with ID 3,  ResourceProfileId 0
[2023-06-25T05:53:31.511+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34571 with 366.3 MiB RAM, BlockManagerId(3, 172.19.0.9, 34571, None)
[2023-06-25T05:53:31.559+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 ERROR TaskSchedulerImpl: Lost an executor 3 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:31.623+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/3 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:31.623+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/3 removed: Command exited with code 1
[2023-06-25T05:53:31.623+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/4 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:31.624+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
[2023-06-25T05:53:31.624+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, 172.19.0.9, 34571, None)
[2023-06-25T05:53:31.624+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/4 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:31.624+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO BlockManagerMaster: Removal of executor 3 requested
[2023-06-25T05:53:31.624+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 3
[2023-06-25T05:53:31.641+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/4 is now RUNNING
[2023-06-25T05:53:33.168+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53570) with ID 4,  ResourceProfileId 0
[2023-06-25T05:53:33.246+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:40867 with 366.3 MiB RAM, BlockManagerId(4, 172.19.0.9, 40867, None)
[2023-06-25T05:53:33.295+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 ERROR TaskSchedulerImpl: Lost executor 4 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:33.300+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO DAGScheduler: Executor lost: 4 (epoch 0)
[2023-06-25T05:53:33.300+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
[2023-06-25T05:53:33.300+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, 172.19.0.9, 40867, None)
[2023-06-25T05:53:33.301+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO BlockManagerMaster: Removed 4 successfully in removeExecutor
[2023-06-25T05:53:33.301+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO DAGScheduler: Shuffle files lost for executor: 4 (epoch 0)
[2023-06-25T05:53:33.351+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/4 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:33.351+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/4 removed: Command exited with code 1
[2023-06-25T05:53:33.351+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
[2023-06-25T05:53:33.351+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO BlockManagerMaster: Removal of executor 4 requested
[2023-06-25T05:53:33.351+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 4
[2023-06-25T05:53:33.352+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/5 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:33.352+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/5 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:33.368+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:33 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/5 is now RUNNING
[2023-06-25T05:53:34.940+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53586) with ID 5,  ResourceProfileId 0
[2023-06-25T05:53:35.016+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34431 with 366.3 MiB RAM, BlockManagerId(5, 172.19.0.9, 34431, None)
[2023-06-25T05:53:35.055+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 ERROR TaskSchedulerImpl: Lost an executor 5 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:35.111+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/5 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:35.111+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/5 removed: Command exited with code 1
[2023-06-25T05:53:35.111+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO BlockManagerMaster: Removal of executor 5 requested
[2023-06-25T05:53:35.111+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 5
[2023-06-25T05:53:35.111+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
[2023-06-25T05:53:35.111+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(5, 172.19.0.9, 34431, None)
[2023-06-25T05:53:35.112+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/6 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:35.112+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/6 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:35.128+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/6 is now RUNNING
[2023-06-25T05:53:36.767+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:59638) with ID 6,  ResourceProfileId 0
[2023-06-25T05:53:36.842+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36647 with 366.3 MiB RAM, BlockManagerId(6, 172.19.0.9, 36647, None)
[2023-06-25T05:53:36.876+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 ERROR TaskSchedulerImpl: Lost an executor 6 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:36.931+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/6 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:36.931+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/6 removed: Command exited with code 1
[2023-06-25T05:53:36.931+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO BlockManagerMaster: Removal of executor 6 requested
[2023-06-25T05:53:36.931+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 6
[2023-06-25T05:53:36.932+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
[2023-06-25T05:53:36.932+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/7 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:36.932+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, 172.19.0.9, 36647, None)
[2023-06-25T05:53:36.932+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/7 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:36.947+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/7 is now RUNNING
[2023-06-25T05:53:38.464+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:59658) with ID 7,  ResourceProfileId 0
[2023-06-25T05:53:38.536+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:45237 with 366.3 MiB RAM, BlockManagerId(7, 172.19.0.9, 45237, None)
[2023-06-25T05:53:38.576+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 ERROR TaskSchedulerImpl: Lost an executor 7 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:38.629+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/7 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:38.629+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/7 removed: Command exited with code 1
[2023-06-25T05:53:38.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO BlockManagerMaster: Removal of executor 7 requested
[2023-06-25T05:53:38.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 7
[2023-06-25T05:53:38.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/8 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:38.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.
[2023-06-25T05:53:38.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(7, 172.19.0.9, 45237, None)
[2023-06-25T05:53:38.631+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/8 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:38.644+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/8 is now RUNNING
[2023-06-25T05:53:40.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:59674) with ID 8,  ResourceProfileId 0
[2023-06-25T05:53:40.321+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:40011 with 366.3 MiB RAM, BlockManagerId(8, 172.19.0.9, 40011, None)
[2023-06-25T05:53:40.359+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 ERROR TaskSchedulerImpl: Lost executor 8 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:40.360+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO DAGScheduler: Executor lost: 8 (epoch 1)
[2023-06-25T05:53:40.360+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO BlockManagerMasterEndpoint: Trying to remove executor 8 from BlockManagerMaster.
[2023-06-25T05:53:40.360+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(8, 172.19.0.9, 40011, None)
[2023-06-25T05:53:40.360+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO BlockManagerMaster: Removed 8 successfully in removeExecutor
[2023-06-25T05:53:40.360+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO DAGScheduler: Shuffle files lost for executor: 8 (epoch 1)
[2023-06-25T05:53:40.412+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/8 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:40.412+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/8 removed: Command exited with code 1
[2023-06-25T05:53:40.412+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO BlockManagerMasterEndpoint: Trying to remove executor 8 from BlockManagerMaster.
[2023-06-25T05:53:40.412+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO BlockManagerMaster: Removal of executor 8 requested
[2023-06-25T05:53:40.413+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 8
[2023-06-25T05:53:40.413+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/9 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:40.413+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/9 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:40.429+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/9 is now RUNNING
[2023-06-25T05:53:42.250+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:59700) with ID 9,  ResourceProfileId 0
[2023-06-25T05:53:42.335+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:41871 with 366.3 MiB RAM, BlockManagerId(9, 172.19.0.9, 41871, None)
[2023-06-25T05:53:42.386+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 ERROR TaskSchedulerImpl: Lost executor 9 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:42.386+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO DAGScheduler: Executor lost: 9 (epoch 2)
[2023-06-25T05:53:42.386+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.
[2023-06-25T05:53:42.386+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(9, 172.19.0.9, 41871, None)
[2023-06-25T05:53:42.386+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO BlockManagerMaster: Removed 9 successfully in removeExecutor
[2023-06-25T05:53:42.387+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO DAGScheduler: Shuffle files lost for executor: 9 (epoch 2)
[2023-06-25T05:53:42.449+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/9 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:42.450+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/9 removed: Command exited with code 1
[2023-06-25T05:53:42.450+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.
[2023-06-25T05:53:42.450+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO BlockManagerMaster: Removal of executor 9 requested
[2023-06-25T05:53:42.450+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 9
[2023-06-25T05:53:42.452+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/10 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:42.452+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/10 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:42.469+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/10 is now RUNNING
[2023-06-25T05:53:44.136+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:59718) with ID 10,  ResourceProfileId 0
[2023-06-25T05:53:44.221+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33871 with 366.3 MiB RAM, BlockManagerId(10, 172.19.0.9, 33871, None)
[2023-06-25T05:53:44.265+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 ERROR TaskSchedulerImpl: Lost an executor 10 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:44.320+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/10 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:44.320+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/10 removed: Command exited with code 1
[2023-06-25T05:53:44.320+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO BlockManagerMasterEndpoint: Trying to remove executor 10 from BlockManagerMaster.
[2023-06-25T05:53:44.321+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO BlockManagerMaster: Removal of executor 10 requested
[2023-06-25T05:53:44.321+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 10
[2023-06-25T05:53:44.321+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(10, 172.19.0.9, 33871, None)
[2023-06-25T05:53:44.321+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/11 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:44.321+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/11 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:44.338+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:44 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/11 is now RUNNING
[2023-06-25T05:53:45.815+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:35570) with ID 11,  ResourceProfileId 0
[2023-06-25T05:53:45.893+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:35593 with 366.3 MiB RAM, BlockManagerId(11, 172.19.0.9, 35593, None)
[2023-06-25T05:53:45.929+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 ERROR TaskSchedulerImpl: Lost an executor 11 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:45.982+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/11 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:45.982+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/11 removed: Command exited with code 1
[2023-06-25T05:53:45.982+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO BlockManagerMasterEndpoint: Trying to remove executor 11 from BlockManagerMaster.
[2023-06-25T05:53:45.982+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO BlockManagerMaster: Removal of executor 11 requested
[2023-06-25T05:53:45.982+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 11
[2023-06-25T05:53:45.983+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(11, 172.19.0.9, 35593, None)
[2023-06-25T05:53:45.983+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/12 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:45.983+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/12 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:45.995+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/12 is now RUNNING
[2023-06-25T05:53:47.573+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:35598) with ID 12,  ResourceProfileId 0
[2023-06-25T05:53:47.667+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:39259 with 366.3 MiB RAM, BlockManagerId(12, 172.19.0.9, 39259, None)
[2023-06-25T05:53:47.709+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 ERROR TaskSchedulerImpl: Lost an executor 12 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:47.767+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/12 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:47.767+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/12 removed: Command exited with code 1
[2023-06-25T05:53:47.767+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO BlockManagerMasterEndpoint: Trying to remove executor 12 from BlockManagerMaster.
[2023-06-25T05:53:47.768+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO BlockManagerMaster: Removal of executor 12 requested
[2023-06-25T05:53:47.768+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 12
[2023-06-25T05:53:47.768+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(12, 172.19.0.9, 39259, None)
[2023-06-25T05:53:47.768+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/13 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:47.768+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/13 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:47.783+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/13 is now RUNNING
[2023-06-25T05:53:49.346+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:35626) with ID 13,  ResourceProfileId 0
[2023-06-25T05:53:49.422+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:38773 with 366.3 MiB RAM, BlockManagerId(13, 172.19.0.9, 38773, None)
[2023-06-25T05:53:49.455+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 ERROR TaskSchedulerImpl: Lost an executor 13 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:49.504+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/13 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:49.505+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/13 removed: Command exited with code 1
[2023-06-25T05:53:49.505+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 13 from BlockManagerMaster.
[2023-06-25T05:53:49.505+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO BlockManagerMaster: Removal of executor 13 requested
[2023-06-25T05:53:49.505+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 13
[2023-06-25T05:53:49.505+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(13, 172.19.0.9, 38773, None)
[2023-06-25T05:53:49.505+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/14 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:49.506+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/14 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:49.519+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/14 is now RUNNING
[2023-06-25T05:53:51.031+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:35650) with ID 14,  ResourceProfileId 0
[2023-06-25T05:53:51.108+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33119 with 366.3 MiB RAM, BlockManagerId(14, 172.19.0.9, 33119, None)
[2023-06-25T05:53:51.142+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 ERROR TaskSchedulerImpl: Lost an executor 14 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:51.191+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/14 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:51.191+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/14 removed: Command exited with code 1
[2023-06-25T05:53:51.191+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO BlockManagerMasterEndpoint: Trying to remove executor 14 from BlockManagerMaster.
[2023-06-25T05:53:51.191+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO BlockManagerMaster: Removal of executor 14 requested
[2023-06-25T05:53:51.192+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 14
[2023-06-25T05:53:51.192+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(14, 172.19.0.9, 33119, None)
[2023-06-25T05:53:51.192+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/15 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:51.192+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/15 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:51.204+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/15 is now RUNNING
[2023-06-25T05:53:52.791+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:35668) with ID 15,  ResourceProfileId 0
[2023-06-25T05:53:52.876+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:42263 with 366.3 MiB RAM, BlockManagerId(15, 172.19.0.9, 42263, None)
[2023-06-25T05:53:52.914+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 ERROR TaskSchedulerImpl: Lost an executor 15 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:52.970+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/15 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/15 removed: Command exited with code 1
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO BlockManagerMaster: Removal of executor 15 requested
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 15
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO BlockManagerMasterEndpoint: Trying to remove executor 15 from BlockManagerMaster.
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(15, 172.19.0.9, 42263, None)
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/16 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:52.971+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/16 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:52.985+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:52 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/16 is now RUNNING
[2023-06-25T05:53:54.626+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:35686) with ID 16,  ResourceProfileId 0
[2023-06-25T05:53:54.714+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33901 with 366.3 MiB RAM, BlockManagerId(16, 172.19.0.9, 33901, None)
[2023-06-25T05:53:54.754+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 ERROR TaskSchedulerImpl: Lost an executor 16 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:54.816+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/16 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:54.816+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/16 removed: Command exited with code 1
[2023-06-25T05:53:54.817+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO BlockManagerMasterEndpoint: Trying to remove executor 16 from BlockManagerMaster.
[2023-06-25T05:53:54.817+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO BlockManagerMaster: Removal of executor 16 requested
[2023-06-25T05:53:54.817+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 16
[2023-06-25T05:53:54.817+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(16, 172.19.0.9, 33901, None)
[2023-06-25T05:53:54.817+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/17 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:54.817+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/17 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:54.832+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/17 is now RUNNING
[2023-06-25T05:53:56.495+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:44642) with ID 17,  ResourceProfileId 0
[2023-06-25T05:53:56.596+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:42751 with 366.3 MiB RAM, BlockManagerId(17, 172.19.0.9, 42751, None)
[2023-06-25T05:53:56.637+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 ERROR TaskSchedulerImpl: Lost an executor 17 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:56.694+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/17 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:56.695+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/17 removed: Command exited with code 1
[2023-06-25T05:53:56.695+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO BlockManagerMasterEndpoint: Trying to remove executor 17 from BlockManagerMaster.
[2023-06-25T05:53:56.695+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO BlockManagerMaster: Removal of executor 17 requested
[2023-06-25T05:53:56.695+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 17
[2023-06-25T05:53:56.695+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(17, 172.19.0.9, 42751, None)
[2023-06-25T05:53:56.695+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/18 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:56.696+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/18 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:56.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/18 is now RUNNING
[2023-06-25T05:53:58.276+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:44660) with ID 18,  ResourceProfileId 0
[2023-06-25T05:53:58.350+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33993 with 366.3 MiB RAM, BlockManagerId(18, 172.19.0.9, 33993, None)
[2023-06-25T05:53:58.391+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 ERROR TaskSchedulerImpl: Lost executor 18 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:53:58.391+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO DAGScheduler: Executor lost: 18 (epoch 3)
[2023-06-25T05:53:58.391+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO BlockManagerMasterEndpoint: Trying to remove executor 18 from BlockManagerMaster.
[2023-06-25T05:53:58.391+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(18, 172.19.0.9, 33993, None)
[2023-06-25T05:53:58.392+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO BlockManagerMaster: Removed 18 successfully in removeExecutor
[2023-06-25T05:53:58.392+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO DAGScheduler: Shuffle files lost for executor: 18 (epoch 3)
[2023-06-25T05:53:58.439+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/18 is now EXITED (Command exited with code 1)
[2023-06-25T05:53:58.439+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/18 removed: Command exited with code 1
[2023-06-25T05:53:58.439+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO BlockManagerMasterEndpoint: Trying to remove executor 18 from BlockManagerMaster.
[2023-06-25T05:53:58.439+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO BlockManagerMaster: Removal of executor 18 requested
[2023-06-25T05:53:58.439+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 18
[2023-06-25T05:53:58.441+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/19 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:53:58.441+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/19 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:53:58.452+0000] {spark_submit.py:492} INFO - 23/06/25 05:53:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/19 is now RUNNING
[2023-06-25T05:54:00.062+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:44684) with ID 19,  ResourceProfileId 0
[2023-06-25T05:54:00.151+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:35761 with 366.3 MiB RAM, BlockManagerId(19, 172.19.0.9, 35761, None)
[2023-06-25T05:54:00.200+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 ERROR TaskSchedulerImpl: Lost an executor 19 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:00.254+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/19 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:00.255+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/19 removed: Command exited with code 1
[2023-06-25T05:54:00.256+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO BlockManagerMasterEndpoint: Trying to remove executor 19 from BlockManagerMaster.
[2023-06-25T05:54:00.256+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/20 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:00.256+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO BlockManagerMaster: Removal of executor 19 requested
[2023-06-25T05:54:00.256+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 19
[2023-06-25T05:54:00.256+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(19, 172.19.0.9, 35761, None)
[2023-06-25T05:54:00.257+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/20 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:00.270+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/20 is now RUNNING
[2023-06-25T05:54:01.926+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:01 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:44708) with ID 20,  ResourceProfileId 0
[2023-06-25T05:54:02.044+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33193 with 366.3 MiB RAM, BlockManagerId(20, 172.19.0.9, 33193, None)
[2023-06-25T05:54:02.091+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 ERROR TaskSchedulerImpl: Lost an executor 20 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:02.145+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/20 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/20 removed: Command exited with code 1
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO BlockManagerMaster: Removal of executor 20 requested
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 20
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO BlockManagerMasterEndpoint: Trying to remove executor 20 from BlockManagerMaster.
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(20, 172.19.0.9, 33193, None)
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/21 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:02.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/21 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:02.161+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/21 is now RUNNING
[2023-06-25T05:54:03.838+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:03 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:44720) with ID 21,  ResourceProfileId 0
[2023-06-25T05:54:03.913+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:03 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:39537 with 366.3 MiB RAM, BlockManagerId(21, 172.19.0.9, 39537, None)
[2023-06-25T05:54:03.953+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:03 ERROR TaskSchedulerImpl: Lost an executor 21 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:04.010+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/21 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:04.010+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/21 removed: Command exited with code 1
[2023-06-25T05:54:04.010+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO BlockManagerMaster: Removal of executor 21 requested
[2023-06-25T05:54:04.011+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 21
[2023-06-25T05:54:04.011+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO BlockManagerMasterEndpoint: Trying to remove executor 21 from BlockManagerMaster.
[2023-06-25T05:54:04.011+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(21, 172.19.0.9, 39537, None)
[2023-06-25T05:54:04.011+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/22 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:04.011+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/22 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:04.027+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/22 is now RUNNING
[2023-06-25T05:54:05.597+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:52782) with ID 22,  ResourceProfileId 0
[2023-06-25T05:54:05.696+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:38819 with 366.3 MiB RAM, BlockManagerId(22, 172.19.0.9, 38819, None)
[2023-06-25T05:54:05.732+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 ERROR TaskSchedulerImpl: Lost an executor 22 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:05.785+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/22 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:05.785+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/22 removed: Command exited with code 1
[2023-06-25T05:54:05.785+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO BlockManagerMaster: Removal of executor 22 requested
[2023-06-25T05:54:05.785+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO BlockManagerMasterEndpoint: Trying to remove executor 22 from BlockManagerMaster.
[2023-06-25T05:54:05.786+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 22
[2023-06-25T05:54:05.786+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(22, 172.19.0.9, 38819, None)
[2023-06-25T05:54:05.786+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/23 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:05.786+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/23 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:05.798+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/23 is now RUNNING
[2023-06-25T05:54:07.516+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:52798) with ID 23,  ResourceProfileId 0
[2023-06-25T05:54:07.640+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33553 with 366.3 MiB RAM, BlockManagerId(23, 172.19.0.9, 33553, None)
[2023-06-25T05:54:07.693+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 ERROR TaskSchedulerImpl: Lost an executor 23 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:07.749+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/23 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:07.749+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/23 removed: Command exited with code 1
[2023-06-25T05:54:07.749+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO BlockManagerMasterEndpoint: Trying to remove executor 23 from BlockManagerMaster.
[2023-06-25T05:54:07.749+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(23, 172.19.0.9, 33553, None)
[2023-06-25T05:54:07.749+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO BlockManagerMaster: Removal of executor 23 requested
[2023-06-25T05:54:07.750+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 23
[2023-06-25T05:54:07.750+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/24 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:07.750+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/24 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:07.765+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/24 is now RUNNING
[2023-06-25T05:54:09.412+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:52818) with ID 24,  ResourceProfileId 0
[2023-06-25T05:54:09.496+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36937 with 366.3 MiB RAM, BlockManagerId(24, 172.19.0.9, 36937, None)
[2023-06-25T05:54:09.532+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 ERROR TaskSchedulerImpl: Lost an executor 24 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:09.585+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/24 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:09.585+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/24 removed: Command exited with code 1
[2023-06-25T05:54:09.585+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO BlockManagerMasterEndpoint: Trying to remove executor 24 from BlockManagerMaster.
[2023-06-25T05:54:09.585+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO BlockManagerMaster: Removal of executor 24 requested
[2023-06-25T05:54:09.585+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 24
[2023-06-25T05:54:09.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(24, 172.19.0.9, 36937, None)
[2023-06-25T05:54:09.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/25 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:09.586+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/25 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:09.597+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:09 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/25 is now RUNNING
[2023-06-25T05:54:11.056+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:52826) with ID 25,  ResourceProfileId 0
[2023-06-25T05:54:11.138+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:32981 with 366.3 MiB RAM, BlockManagerId(25, 172.19.0.9, 32981, None)
[2023-06-25T05:54:11.181+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 ERROR TaskSchedulerImpl: Lost an executor 25 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:11.233+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/25 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:11.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/25 removed: Command exited with code 1
[2023-06-25T05:54:11.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO BlockManagerMasterEndpoint: Trying to remove executor 25 from BlockManagerMaster.
[2023-06-25T05:54:11.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO BlockManagerMaster: Removal of executor 25 requested
[2023-06-25T05:54:11.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 25
[2023-06-25T05:54:11.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(25, 172.19.0.9, 32981, None)
[2023-06-25T05:54:11.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/26 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:11.235+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/26 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:11.247+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:11 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/26 is now RUNNING
[2023-06-25T05:54:12.877+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:52852) with ID 26,  ResourceProfileId 0
[2023-06-25T05:54:12.958+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:12 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:35801 with 366.3 MiB RAM, BlockManagerId(26, 172.19.0.9, 35801, None)
[2023-06-25T05:54:12.998+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:12 ERROR TaskSchedulerImpl: Lost an executor 26 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:13.132+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/26 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:13.132+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/26 removed: Command exited with code 1
[2023-06-25T05:54:13.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO BlockManagerMaster: Removal of executor 26 requested
[2023-06-25T05:54:13.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 26
[2023-06-25T05:54:13.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO BlockManagerMasterEndpoint: Trying to remove executor 26 from BlockManagerMaster.
[2023-06-25T05:54:13.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(26, 172.19.0.9, 35801, None)
[2023-06-25T05:54:13.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/27 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:13.133+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/27 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:13.146+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/27 is now RUNNING
[2023-06-25T05:54:14.665+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:52876) with ID 27,  ResourceProfileId 0
[2023-06-25T05:54:14.747+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:37505 with 366.3 MiB RAM, BlockManagerId(27, 172.19.0.9, 37505, None)
[2023-06-25T05:54:14.782+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 ERROR TaskSchedulerImpl: Lost an executor 27 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:14.836+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/27 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:14.836+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/27 removed: Command exited with code 1
[2023-06-25T05:54:14.837+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO BlockManagerMaster: Removal of executor 27 requested
[2023-06-25T05:54:14.837+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 27
[2023-06-25T05:54:14.837+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO BlockManagerMasterEndpoint: Trying to remove executor 27 from BlockManagerMaster.
[2023-06-25T05:54:14.837+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/28 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:14.837+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(27, 172.19.0.9, 37505, None)
[2023-06-25T05:54:14.837+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/28 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:14.850+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:14 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/28 is now RUNNING
[2023-06-25T05:54:16.358+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:43706) with ID 28,  ResourceProfileId 0
[2023-06-25T05:54:16.434+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36205 with 366.3 MiB RAM, BlockManagerId(28, 172.19.0.9, 36205, None)
[2023-06-25T05:54:16.474+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 ERROR TaskSchedulerImpl: Lost an executor 28 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:16.548+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/28 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:16.549+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/28 removed: Command exited with code 1
[2023-06-25T05:54:16.549+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO BlockManagerMasterEndpoint: Trying to remove executor 28 from BlockManagerMaster.
[2023-06-25T05:54:16.549+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO BlockManagerMaster: Removal of executor 28 requested
[2023-06-25T05:54:16.549+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 28
[2023-06-25T05:54:16.550+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(28, 172.19.0.9, 36205, None)
[2023-06-25T05:54:16.550+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/29 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:16.550+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/29 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:16.563+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:16 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/29 is now RUNNING
[2023-06-25T05:54:18.107+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:43722) with ID 29,  ResourceProfileId 0
[2023-06-25T05:54:18.188+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36071 with 366.3 MiB RAM, BlockManagerId(29, 172.19.0.9, 36071, None)
[2023-06-25T05:54:18.225+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 ERROR TaskSchedulerImpl: Lost an executor 29 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:18.277+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/29 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:18.278+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/29 removed: Command exited with code 1
[2023-06-25T05:54:18.278+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO BlockManagerMaster: Removal of executor 29 requested
[2023-06-25T05:54:18.278+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 29
[2023-06-25T05:54:18.278+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO BlockManagerMasterEndpoint: Trying to remove executor 29 from BlockManagerMaster.
[2023-06-25T05:54:18.278+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(29, 172.19.0.9, 36071, None)
[2023-06-25T05:54:18.279+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/30 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:18.279+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/30 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:18.291+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/30 is now RUNNING
[2023-06-25T05:54:20.059+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:43738) with ID 30,  ResourceProfileId 0
[2023-06-25T05:54:20.143+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:42977 with 366.3 MiB RAM, BlockManagerId(30, 172.19.0.9, 42977, None)
[2023-06-25T05:54:20.182+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 ERROR TaskSchedulerImpl: Lost an executor 30 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:20.263+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/30 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:20.263+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/30 removed: Command exited with code 1
[2023-06-25T05:54:20.263+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO BlockManagerMaster: Removal of executor 30 requested
[2023-06-25T05:54:20.263+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 30
[2023-06-25T05:54:20.263+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO BlockManagerMasterEndpoint: Trying to remove executor 30 from BlockManagerMaster.
[2023-06-25T05:54:20.264+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(30, 172.19.0.9, 42977, None)
[2023-06-25T05:54:20.264+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/31 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:20.264+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/31 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:20.277+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:20 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/31 is now RUNNING
[2023-06-25T05:54:22.047+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:43756) with ID 31,  ResourceProfileId 0
[2023-06-25T05:54:22.130+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34341 with 366.3 MiB RAM, BlockManagerId(31, 172.19.0.9, 34341, None)
[2023-06-25T05:54:22.176+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 ERROR TaskSchedulerImpl: Lost an executor 31 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:22.242+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/31 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:22.242+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/31 removed: Command exited with code 1
[2023-06-25T05:54:22.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO BlockManagerMasterEndpoint: Trying to remove executor 31 from BlockManagerMaster.
[2023-06-25T05:54:22.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO BlockManagerMaster: Removal of executor 31 requested
[2023-06-25T05:54:22.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 31
[2023-06-25T05:54:22.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(31, 172.19.0.9, 34341, None)
[2023-06-25T05:54:22.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/32 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:22.243+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/32 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:22.256+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/32 is now RUNNING
[2023-06-25T05:54:23.869+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:23 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:43768) with ID 32,  ResourceProfileId 0
[2023-06-25T05:54:23.988+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:23 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:39547 with 366.3 MiB RAM, BlockManagerId(32, 172.19.0.9, 39547, None)
[2023-06-25T05:54:24.029+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 ERROR TaskSchedulerImpl: Lost an executor 32 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:24.086+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/32 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:24.086+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/32 removed: Command exited with code 1
[2023-06-25T05:54:24.086+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO BlockManagerMasterEndpoint: Trying to remove executor 32 from BlockManagerMaster.
[2023-06-25T05:54:24.086+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO BlockManagerMaster: Removal of executor 32 requested
[2023-06-25T05:54:24.087+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 32
[2023-06-25T05:54:24.087+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/33 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:24.087+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(32, 172.19.0.9, 39547, None)
[2023-06-25T05:54:24.087+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/33 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:24.099+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/33 is now RUNNING
[2023-06-25T05:54:25.896+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:25 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:56514) with ID 33,  ResourceProfileId 0
[2023-06-25T05:54:25.999+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:25 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44443 with 366.3 MiB RAM, BlockManagerId(33, 172.19.0.9, 44443, None)
[2023-06-25T05:54:26.054+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 ERROR TaskSchedulerImpl: Lost an executor 33 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:26.136+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/33 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:26.136+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/33 removed: Command exited with code 1
[2023-06-25T05:54:26.136+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO BlockManagerMasterEndpoint: Trying to remove executor 33 from BlockManagerMaster.
[2023-06-25T05:54:26.136+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO BlockManagerMaster: Removal of executor 33 requested
[2023-06-25T05:54:26.137+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 33
[2023-06-25T05:54:26.137+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/34 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:26.137+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(33, 172.19.0.9, 44443, None)
[2023-06-25T05:54:26.137+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/34 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:26.155+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/34 is now RUNNING
[2023-06-25T05:54:27.777+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:56538) with ID 34,  ResourceProfileId 0
[2023-06-25T05:54:27.862+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36971 with 366.3 MiB RAM, BlockManagerId(34, 172.19.0.9, 36971, None)
[2023-06-25T05:54:27.908+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 ERROR TaskSchedulerImpl: Lost an executor 34 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:27.973+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/34 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:27.973+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/34 removed: Command exited with code 1
[2023-06-25T05:54:27.974+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO BlockManagerMasterEndpoint: Trying to remove executor 34 from BlockManagerMaster.
[2023-06-25T05:54:27.974+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO BlockManagerMaster: Removal of executor 34 requested
[2023-06-25T05:54:27.974+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 34
[2023-06-25T05:54:27.974+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(34, 172.19.0.9, 36971, None)
[2023-06-25T05:54:27.974+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/35 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:27.974+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/35 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:27.986+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/35 is now RUNNING
[2023-06-25T05:54:29.536+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:56562) with ID 35,  ResourceProfileId 0
[2023-06-25T05:54:29.611+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36185 with 366.3 MiB RAM, BlockManagerId(35, 172.19.0.9, 36185, None)
[2023-06-25T05:54:29.653+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 ERROR TaskSchedulerImpl: Lost an executor 35 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:29.700+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/35 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/35 removed: Command exited with code 1
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO BlockManagerMasterEndpoint: Trying to remove executor 35 from BlockManagerMaster.
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO BlockManagerMaster: Removal of executor 35 requested
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 35
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(35, 172.19.0.9, 36185, None)
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/36 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:29.701+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/36 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:29.713+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/36 is now RUNNING
[2023-06-25T05:54:31.284+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:56576) with ID 36,  ResourceProfileId 0
[2023-06-25T05:54:31.369+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36909 with 366.3 MiB RAM, BlockManagerId(36, 172.19.0.9, 36909, None)
[2023-06-25T05:54:31.415+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 ERROR TaskSchedulerImpl: Lost executor 36 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:31.416+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO DAGScheduler: Executor lost: 36 (epoch 4)
[2023-06-25T05:54:31.416+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO BlockManagerMasterEndpoint: Trying to remove executor 36 from BlockManagerMaster.
[2023-06-25T05:54:31.416+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(36, 172.19.0.9, 36909, None)
[2023-06-25T05:54:31.416+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO BlockManagerMaster: Removed 36 successfully in removeExecutor
[2023-06-25T05:54:31.416+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO DAGScheduler: Shuffle files lost for executor: 36 (epoch 4)
[2023-06-25T05:54:31.473+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/36 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:31.474+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/36 removed: Command exited with code 1
[2023-06-25T05:54:31.474+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO BlockManagerMasterEndpoint: Trying to remove executor 36 from BlockManagerMaster.
[2023-06-25T05:54:31.474+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO BlockManagerMaster: Removal of executor 36 requested
[2023-06-25T05:54:31.474+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 36
[2023-06-25T05:54:31.474+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/37 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:31.475+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/37 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:31.488+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/37 is now RUNNING
[2023-06-25T05:54:33.785+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:33 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:56586) with ID 37,  ResourceProfileId 0
[2023-06-25T05:54:33.916+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:33 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:42669 with 366.3 MiB RAM, BlockManagerId(37, 172.19.0.9, 42669, None)
[2023-06-25T05:54:33.969+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:33 ERROR TaskSchedulerImpl: Lost an executor 37 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:34.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/37 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/37 removed: Command exited with code 1
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/38 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO BlockManagerMasterEndpoint: Trying to remove executor 37 from BlockManagerMaster.
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO BlockManagerMaster: Removal of executor 37 requested
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 37
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(37, 172.19.0.9, 42669, None)
[2023-06-25T05:54:34.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/38 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:34.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/38 is now RUNNING
[2023-06-25T05:54:35.874+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:35 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:54882) with ID 38,  ResourceProfileId 0
[2023-06-25T05:54:35.957+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:35 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44663 with 366.3 MiB RAM, BlockManagerId(38, 172.19.0.9, 44663, None)
[2023-06-25T05:54:35.996+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:35 ERROR TaskSchedulerImpl: Lost an executor 38 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:36.047+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/38 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:36.047+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/38 removed: Command exited with code 1
[2023-06-25T05:54:36.047+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO BlockManagerMasterEndpoint: Trying to remove executor 38 from BlockManagerMaster.
[2023-06-25T05:54:36.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO BlockManagerMaster: Removal of executor 38 requested
[2023-06-25T05:54:36.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 38
[2023-06-25T05:54:36.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(38, 172.19.0.9, 44663, None)
[2023-06-25T05:54:36.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/39 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:36.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/39 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:36.063+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:36 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/39 is now RUNNING
[2023-06-25T05:54:37.775+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:54898) with ID 39,  ResourceProfileId 0
[2023-06-25T05:54:37.858+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:37163 with 366.3 MiB RAM, BlockManagerId(39, 172.19.0.9, 37163, None)
[2023-06-25T05:54:37.895+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 ERROR TaskSchedulerImpl: Lost an executor 39 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/39 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/39 removed: Command exited with code 1
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO BlockManagerMaster: Removal of executor 39 requested
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 39
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO BlockManagerMasterEndpoint: Trying to remove executor 39 from BlockManagerMaster.
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(39, 172.19.0.9, 37163, None)
[2023-06-25T05:54:37.948+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/40 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:37.949+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/40 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:37.961+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:37 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/40 is now RUNNING
[2023-06-25T05:54:39.559+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:54914) with ID 40,  ResourceProfileId 0
[2023-06-25T05:54:39.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34723 with 366.3 MiB RAM, BlockManagerId(40, 172.19.0.9, 34723, None)
[2023-06-25T05:54:39.673+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 ERROR TaskSchedulerImpl: Lost an executor 40 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:39.737+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/40 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:39.737+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/40 removed: Command exited with code 1
[2023-06-25T05:54:39.737+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO BlockManagerMasterEndpoint: Trying to remove executor 40 from BlockManagerMaster.
[2023-06-25T05:54:39.737+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO BlockManagerMaster: Removal of executor 40 requested
[2023-06-25T05:54:39.737+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 40
[2023-06-25T05:54:39.738+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(40, 172.19.0.9, 34723, None)
[2023-06-25T05:54:39.738+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/41 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:39.738+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/41 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:39.749+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/41 is now RUNNING
[2023-06-25T05:54:41.329+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:54934) with ID 41,  ResourceProfileId 0
[2023-06-25T05:54:41.419+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:46769 with 366.3 MiB RAM, BlockManagerId(41, 172.19.0.9, 46769, None)
[2023-06-25T05:54:41.458+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 ERROR TaskSchedulerImpl: Lost an executor 41 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:41.509+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/41 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:41.509+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/41 removed: Command exited with code 1
[2023-06-25T05:54:41.509+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO BlockManagerMasterEndpoint: Trying to remove executor 41 from BlockManagerMaster.
[2023-06-25T05:54:41.509+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/42 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:41.509+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO BlockManagerMaster: Removal of executor 41 requested
[2023-06-25T05:54:41.509+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 41
[2023-06-25T05:54:41.510+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(41, 172.19.0.9, 46769, None)
[2023-06-25T05:54:41.510+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/42 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:41.521+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/42 is now RUNNING
[2023-06-25T05:54:43.183+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:54956) with ID 42,  ResourceProfileId 0
[2023-06-25T05:54:43.258+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:38335 with 366.3 MiB RAM, BlockManagerId(42, 172.19.0.9, 38335, None)
[2023-06-25T05:54:43.297+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 ERROR TaskSchedulerImpl: Lost executor 42 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:43.298+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO DAGScheduler: Executor lost: 42 (epoch 5)
[2023-06-25T05:54:43.298+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO BlockManagerMasterEndpoint: Trying to remove executor 42 from BlockManagerMaster.
[2023-06-25T05:54:43.298+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(42, 172.19.0.9, 38335, None)
[2023-06-25T05:54:43.298+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO BlockManagerMaster: Removed 42 successfully in removeExecutor
[2023-06-25T05:54:43.299+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO DAGScheduler: Shuffle files lost for executor: 42 (epoch 5)
[2023-06-25T05:54:43.352+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/42 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:43.352+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/42 removed: Command exited with code 1
[2023-06-25T05:54:43.352+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/43 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:43.353+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO BlockManagerMaster: Removal of executor 42 requested
[2023-06-25T05:54:43.353+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 42
[2023-06-25T05:54:43.353+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/43 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:43.353+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO BlockManagerMasterEndpoint: Trying to remove executor 42 from BlockManagerMaster.
[2023-06-25T05:54:43.387+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/43 is now RUNNING
[2023-06-25T05:54:45.058+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:54972) with ID 43,  ResourceProfileId 0
[2023-06-25T05:54:45.134+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:43619 with 366.3 MiB RAM, BlockManagerId(43, 172.19.0.9, 43619, None)
[2023-06-25T05:54:45.177+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 ERROR TaskSchedulerImpl: Lost an executor 43 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:45.228+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/43 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:45.228+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/43 removed: Command exited with code 1
[2023-06-25T05:54:45.228+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO BlockManagerMasterEndpoint: Trying to remove executor 43 from BlockManagerMaster.
[2023-06-25T05:54:45.228+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO BlockManagerMaster: Removal of executor 43 requested
[2023-06-25T05:54:45.229+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 43
[2023-06-25T05:54:45.229+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(43, 172.19.0.9, 43619, None)
[2023-06-25T05:54:45.229+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/44 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:45.229+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/44 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:45.240+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/44 is now RUNNING
[2023-06-25T05:54:47.112+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:38008) with ID 44,  ResourceProfileId 0
[2023-06-25T05:54:47.194+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:42539 with 366.3 MiB RAM, BlockManagerId(44, 172.19.0.9, 42539, None)
[2023-06-25T05:54:47.238+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 ERROR TaskSchedulerImpl: Lost an executor 44 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:47.324+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/44 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:47.324+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/44 removed: Command exited with code 1
[2023-06-25T05:54:47.326+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/45 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:47.327+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/45 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:47.327+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO BlockManagerMasterEndpoint: Trying to remove executor 44 from BlockManagerMaster.
[2023-06-25T05:54:47.327+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(44, 172.19.0.9, 42539, None)
[2023-06-25T05:54:47.328+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO BlockManagerMaster: Removal of executor 44 requested
[2023-06-25T05:54:47.328+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 44
[2023-06-25T05:54:47.380+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:47 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/45 is now RUNNING
[2023-06-25T05:54:49.000+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:38030) with ID 45,  ResourceProfileId 0
[2023-06-25T05:54:49.082+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44701 with 366.3 MiB RAM, BlockManagerId(45, 172.19.0.9, 44701, None)
[2023-06-25T05:54:49.118+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 ERROR TaskSchedulerImpl: Lost an executor 45 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:49.171+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/45 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:49.171+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/45 removed: Command exited with code 1
[2023-06-25T05:54:49.171+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO BlockManagerMasterEndpoint: Trying to remove executor 45 from BlockManagerMaster.
[2023-06-25T05:54:49.171+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO BlockManagerMaster: Removal of executor 45 requested
[2023-06-25T05:54:49.171+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 45
[2023-06-25T05:54:49.172+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(45, 172.19.0.9, 44701, None)
[2023-06-25T05:54:49.172+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/46 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:49.172+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/46 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:49.183+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/46 is now RUNNING
[2023-06-25T05:54:50.835+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:50 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:38038) with ID 46,  ResourceProfileId 0
[2023-06-25T05:54:50.930+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:50 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44367 with 366.3 MiB RAM, BlockManagerId(46, 172.19.0.9, 44367, None)
[2023-06-25T05:54:50.973+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:50 ERROR TaskSchedulerImpl: Lost an executor 46 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:51.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/46 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:51.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/46 removed: Command exited with code 1
[2023-06-25T05:54:51.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO BlockManagerMasterEndpoint: Trying to remove executor 46 from BlockManagerMaster.
[2023-06-25T05:54:51.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO BlockManagerMaster: Removal of executor 46 requested
[2023-06-25T05:54:51.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 46
[2023-06-25T05:54:51.035+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(46, 172.19.0.9, 44367, None)
[2023-06-25T05:54:51.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/47 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:51.036+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/47 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:51.048+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:51 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/47 is now RUNNING
[2023-06-25T05:54:52.751+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:38056) with ID 47,  ResourceProfileId 0
[2023-06-25T05:54:52.839+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34471 with 366.3 MiB RAM, BlockManagerId(47, 172.19.0.9, 34471, None)
[2023-06-25T05:54:52.881+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 ERROR TaskSchedulerImpl: Lost an executor 47 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:52.932+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/47 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:52.933+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/47 removed: Command exited with code 1
[2023-06-25T05:54:52.933+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO BlockManagerMasterEndpoint: Trying to remove executor 47 from BlockManagerMaster.
[2023-06-25T05:54:52.933+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO BlockManagerMaster: Removal of executor 47 requested
[2023-06-25T05:54:52.934+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 47
[2023-06-25T05:54:52.934+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(47, 172.19.0.9, 34471, None)
[2023-06-25T05:54:52.934+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/48 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:52.934+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/48 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:52.945+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:52 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/48 is now RUNNING
[2023-06-25T05:54:54.533+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:38084) with ID 48,  ResourceProfileId 0
[2023-06-25T05:54:54.624+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:42091 with 366.3 MiB RAM, BlockManagerId(48, 172.19.0.9, 42091, None)
[2023-06-25T05:54:54.661+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 ERROR TaskSchedulerImpl: Lost an executor 48 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/48 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/48 removed: Command exited with code 1
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO BlockManagerMaster: Removal of executor 48 requested
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO BlockManagerMasterEndpoint: Trying to remove executor 48 from BlockManagerMaster.
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 48
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(48, 172.19.0.9, 42091, None)
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/49 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:54.710+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/49 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:54.722+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/49 is now RUNNING
[2023-06-25T05:54:56.248+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:40296) with ID 49,  ResourceProfileId 0
[2023-06-25T05:54:56.327+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:33881 with 366.3 MiB RAM, BlockManagerId(49, 172.19.0.9, 33881, None)
[2023-06-25T05:54:56.376+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 ERROR TaskSchedulerImpl: Lost executor 49 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:56.376+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO DAGScheduler: Executor lost: 49 (epoch 6)
[2023-06-25T05:54:56.377+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO BlockManagerMasterEndpoint: Trying to remove executor 49 from BlockManagerMaster.
[2023-06-25T05:54:56.377+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(49, 172.19.0.9, 33881, None)
[2023-06-25T05:54:56.377+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO BlockManagerMaster: Removed 49 successfully in removeExecutor
[2023-06-25T05:54:56.377+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO DAGScheduler: Shuffle files lost for executor: 49 (epoch 6)
[2023-06-25T05:54:56.445+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/49 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:56.445+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/49 removed: Command exited with code 1
[2023-06-25T05:54:56.446+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO BlockManagerMaster: Removal of executor 49 requested
[2023-06-25T05:54:56.446+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 49
[2023-06-25T05:54:56.446+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO BlockManagerMasterEndpoint: Trying to remove executor 49 from BlockManagerMaster.
[2023-06-25T05:54:56.446+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/50 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:56.446+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/50 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:56.459+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/50 is now RUNNING
[2023-06-25T05:54:58.328+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:40304) with ID 50,  ResourceProfileId 0
[2023-06-25T05:54:58.449+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34679 with 366.3 MiB RAM, BlockManagerId(50, 172.19.0.9, 34679, None)
[2023-06-25T05:54:58.533+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 ERROR TaskSchedulerImpl: Lost an executor 50 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:54:58.613+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/50 is now EXITED (Command exited with code 1)
[2023-06-25T05:54:58.613+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/50 removed: Command exited with code 1
[2023-06-25T05:54:58.613+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO BlockManagerMaster: Removal of executor 50 requested
[2023-06-25T05:54:58.613+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 50
[2023-06-25T05:54:58.613+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO BlockManagerMasterEndpoint: Trying to remove executor 50 from BlockManagerMaster.
[2023-06-25T05:54:58.613+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/51 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:54:58.614+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(50, 172.19.0.9, 34679, None)
[2023-06-25T05:54:58.614+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/51 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:54:58.640+0000] {spark_submit.py:492} INFO - 23/06/25 05:54:58 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/51 is now RUNNING
[2023-06-25T05:55:00.502+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:40310) with ID 51,  ResourceProfileId 0
[2023-06-25T05:55:00.588+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:34123 with 366.3 MiB RAM, BlockManagerId(51, 172.19.0.9, 34123, None)
[2023-06-25T05:55:00.630+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 ERROR TaskSchedulerImpl: Lost an executor 51 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:00.681+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/51 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:00.681+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/51 removed: Command exited with code 1
[2023-06-25T05:55:00.681+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO BlockManagerMasterEndpoint: Trying to remove executor 51 from BlockManagerMaster.
[2023-06-25T05:55:00.681+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO BlockManagerMaster: Removal of executor 51 requested
[2023-06-25T05:55:00.681+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 51
[2023-06-25T05:55:00.681+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(51, 172.19.0.9, 34123, None)
[2023-06-25T05:55:00.682+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/52 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:00.682+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/52 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:00.693+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:00 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/52 is now RUNNING
[2023-06-25T05:55:02.343+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:40316) with ID 52,  ResourceProfileId 0
[2023-06-25T05:55:02.422+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:45781 with 366.3 MiB RAM, BlockManagerId(52, 172.19.0.9, 45781, None)
[2023-06-25T05:55:02.467+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 ERROR TaskSchedulerImpl: Lost an executor 52 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:02.517+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/52 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:02.517+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/52 removed: Command exited with code 1
[2023-06-25T05:55:02.517+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO BlockManagerMasterEndpoint: Trying to remove executor 52 from BlockManagerMaster.
[2023-06-25T05:55:02.518+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO BlockManagerMaster: Removal of executor 52 requested
[2023-06-25T05:55:02.518+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 52
[2023-06-25T05:55:02.518+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(52, 172.19.0.9, 45781, None)
[2023-06-25T05:55:02.518+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/53 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:02.518+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/53 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:02.528+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:02 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/53 is now RUNNING
[2023-06-25T05:55:04.340+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:40340) with ID 53,  ResourceProfileId 0
[2023-06-25T05:55:04.420+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36111 with 366.3 MiB RAM, BlockManagerId(53, 172.19.0.9, 36111, None)
[2023-06-25T05:55:04.459+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 ERROR TaskSchedulerImpl: Lost an executor 53 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:04.536+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/53 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/53 removed: Command exited with code 1
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO BlockManagerMasterEndpoint: Trying to remove executor 53 from BlockManagerMaster.
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO BlockManagerMaster: Removal of executor 53 requested
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 53
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(53, 172.19.0.9, 36111, None)
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/54 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:04.537+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/54 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:04.551+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:04 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/54 is now RUNNING
[2023-06-25T05:55:06.127+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53264) with ID 54,  ResourceProfileId 0
[2023-06-25T05:55:06.198+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:36061 with 366.3 MiB RAM, BlockManagerId(54, 172.19.0.9, 36061, None)
[2023-06-25T05:55:06.231+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 ERROR TaskSchedulerImpl: Lost an executor 54 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/54 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/54 removed: Command exited with code 1
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO BlockManagerMasterEndpoint: Trying to remove executor 54 from BlockManagerMaster.
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO BlockManagerMaster: Removal of executor 54 requested
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 54
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(54, 172.19.0.9, 36061, None)
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/55 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:06.280+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/55 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:06.290+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/55 is now RUNNING
[2023-06-25T05:55:08.027+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53280) with ID 55,  ResourceProfileId 0
[2023-06-25T05:55:08.102+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:46229 with 366.3 MiB RAM, BlockManagerId(55, 172.19.0.9, 46229, None)
[2023-06-25T05:55:08.154+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 ERROR TaskSchedulerImpl: Lost an executor 55 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:08.229+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/55 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:08.230+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/55 removed: Command exited with code 1
[2023-06-25T05:55:08.230+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO BlockManagerMaster: Removal of executor 55 requested
[2023-06-25T05:55:08.230+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 55
[2023-06-25T05:55:08.230+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO BlockManagerMasterEndpoint: Trying to remove executor 55 from BlockManagerMaster.
[2023-06-25T05:55:08.230+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(55, 172.19.0.9, 46229, None)
[2023-06-25T05:55:08.231+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/56 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:08.231+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/56 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:08.242+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/56 is now RUNNING
[2023-06-25T05:55:10.217+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53300) with ID 56,  ResourceProfileId 0
[2023-06-25T05:55:10.344+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44677 with 366.3 MiB RAM, BlockManagerId(56, 172.19.0.9, 44677, None)
[2023-06-25T05:55:10.405+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 ERROR TaskSchedulerImpl: Lost executor 56 on 172.19.0.9: Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:10.405+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO DAGScheduler: Executor lost: 56 (epoch 7)
[2023-06-25T05:55:10.405+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO BlockManagerMasterEndpoint: Trying to remove executor 56 from BlockManagerMaster.
[2023-06-25T05:55:10.405+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(56, 172.19.0.9, 44677, None)
[2023-06-25T05:55:10.406+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO BlockManagerMaster: Removed 56 successfully in removeExecutor
[2023-06-25T05:55:10.406+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO DAGScheduler: Shuffle files lost for executor: 56 (epoch 7)
[2023-06-25T05:55:10.507+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/56 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:10.507+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/56 removed: Command exited with code 1
[2023-06-25T05:55:10.507+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/57 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:10.507+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/57 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:10.508+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO BlockManagerMasterEndpoint: Trying to remove executor 56 from BlockManagerMaster.
[2023-06-25T05:55:10.508+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO BlockManagerMaster: Removal of executor 56 requested
[2023-06-25T05:55:10.508+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 56
[2023-06-25T05:55:10.525+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:10 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/57 is now RUNNING
[2023-06-25T05:55:12.953+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:12 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:53324) with ID 57,  ResourceProfileId 0
[2023-06-25T05:55:13.070+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:35617 with 366.3 MiB RAM, BlockManagerId(57, 172.19.0.9, 35617, None)
[2023-06-25T05:55:13.138+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 ERROR TaskSchedulerImpl: Lost an executor 57 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:13.233+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/57 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/57 removed: Command exited with code 1
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO BlockManagerMasterEndpoint: Trying to remove executor 57 from BlockManagerMaster.
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO BlockManagerMaster: Removal of executor 57 requested
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 57
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/58 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(57, 172.19.0.9, 35617, None)
[2023-06-25T05:55:13.234+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/58 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:13.246+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/58 is now RUNNING
[2023-06-25T05:55:15.470+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:45032) with ID 58,  ResourceProfileId 0
[2023-06-25T05:55:15.596+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44975 with 366.3 MiB RAM, BlockManagerId(58, 172.19.0.9, 44975, None)
[2023-06-25T05:55:15.658+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 ERROR TaskSchedulerImpl: Lost an executor 58 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:15.754+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/58 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/58 removed: Command exited with code 1
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO BlockManagerMaster: Removal of executor 58 requested
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 58
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO BlockManagerMasterEndpoint: Trying to remove executor 58 from BlockManagerMaster.
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(58, 172.19.0.9, 44975, None)
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/59 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:15.755+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/59 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:15.769+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:15 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/59 is now RUNNING
[2023-06-25T05:55:17.791+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:17 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.19.0.9:45056) with ID 59,  ResourceProfileId 0
[2023-06-25T05:55:17.902+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:17 INFO BlockManagerMasterEndpoint: Registering block manager 172.19.0.9:44957 with 366.3 MiB RAM, BlockManagerId(59, 172.19.0.9, 44957, None)
[2023-06-25T05:55:17.942+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:17 ERROR TaskSchedulerImpl: Lost an executor 59 (already removed): Unable to create executor due to /opt/spark/jars/aws-java-sdk-bundle-1.11.375.jar
[2023-06-25T05:55:18.016+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/59 is now EXITED (Command exited with code 1)
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO StandaloneSchedulerBackend: Executor app-20230625055322-0001/59 removed: Command exited with code 1
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO BlockManagerMasterEndpoint: Trying to remove executor 59 from BlockManagerMaster.
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO BlockManagerMaster: Removal of executor 59 requested
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asked to remove non-existent executor 59
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(59, 172.19.0.9, 44957, None)
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20230625055322-0001/60 on worker-20230625055131-172.19.0.9-42181 (172.19.0.9:42181) with 1 core(s)
[2023-06-25T05:55:18.017+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20230625055322-0001/60 on hostPort 172.19.0.9:42181 with 1 core(s), 1024.0 MiB RAM
[2023-06-25T05:55:18.029+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20230625055322-0001/60 is now RUNNING
[2023-06-25T05:55:19.443+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:19 WARN StandaloneAppClient$ClientEndpoint: Connection to 0b67bc54c547:7077 failed; waiting for master to reconnect...
[2023-06-25T05:55:19.443+0000] {spark_submit.py:492} INFO - 23/06/25 05:55:19 WARN StandaloneSchedulerBackend: Disconnected from Spark cluster! Waiting for reconnection...
[2023-06-25T06:21:49.391+0000] {spark_submit.py:492} INFO - 23/06/25 06:21:49 INFO AsyncEventQueue: Process of event SparkListenerExecutorMetricsUpdate(driver,WrappedArray(),Map((-1,-1) -> org.apache.spark.executor.ExecutorMetrics@468803e2)) by listener AppStatusListener took 1.657233289s.
[2023-06-25T06:21:43.815+0000] {base_job.py:243} ERROR - LocalTaskJob heartbeat got an exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not translate host name "postgres" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/base_job.py", line 215, in heartbeat
    session.merge(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3051, in merge
    return self._merge(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 3131, in _merge
    merged = self.get(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2848, in get
    return self._get_impl(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 2970, in _get_impl
    return db_load_fn(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/loading.py", line 530, in load_on_pk_identity
    session.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1713, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1552, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 747, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3315, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3394, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3364, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2198, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3361, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 578, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "postgres" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
